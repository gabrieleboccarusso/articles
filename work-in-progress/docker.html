<!-- title: Docker from the ground up -->

<p>
   Once an application is developed or, at least, reaches a fully derivable state, comes the deployment phase. Everything that happens between the making of a software application and its deployment is defined as <i>operations</i>. The operations teams and the development teams used to have important differences between them and this did not make for a smooth deployment of a software product so new tools and ways to operate were invented to make such processes run smoother. Such discipline took the name of <i>devops</i> due to how close to development it was while still maintaining the focus on the operations.
</p>

<h2>What is DevOps?</h2>
<p>
 Docker is getting everyday more relevant into the world of DevOps and to fully understand it it's important to make clear what DevOps is and what role it plays into the modern software development scene. <i>Dev</i> refers to software development and <i>Ops</i> to the related operations such as the release, the monitoring and the packaging. It bridges the gap between the development and these operations using a set of precise practices aimed to improve the workflow between quality assurance, continuous development and continuous integration of the software throughout its whole lifecycle.
</p>
<span class="image">
   <img src="https://i.ibb.co/C136rNH/img1.jpg" alt="visual rapresentation of the devops cycle of release and production">
</span>

<h2>What is Docker?</h2>
<p>
 Docker is a platform that uses virtualization at the operative system level to deliver software in lightweight packages called containers. A docker container contains mainly two things:
 <ul>
  <li>The software source code</li>
  <li>The perative System binary files and libraries</li>
 </ul>
 These two things, although being in the same container, are throughly separated so to not interfere with each other or other dependencies. If such need would eventually arise Docker offers way and tools to <i>orchestrate</i> everything is an easy way.
</p>
<p>
   A container is an instance of an <i>image</i>. An image is a factory that creates containers and it is created from a <code>Dockerfile</code>, the file present into the project's directory and that once built creates an image ready to instantiate containers. A container is the actually packaged project.
</p>
<span class="image">
   <img src="https://i.ibb.co/3T25BQh/img2.jpg" alt="visual rapresentation of a containerized application">
</span>

<h2>Docker's benefits</h2>
<p>
 Containerizing an application provides multiple benefits. The first is that it makes an application agnostic from both the computer where it is developed and the server where it will be deployed. With the container already containing all that is needed to run the application there is the certainty that it will run the same on the development machine, on the server and on every different platform it is used thus being indipendent from the outside environment. 
</p>
<p>
 If a software needs a dependency as, for example, a specific version of a database, there will be no problem and difference between deployment and production as a container can also refer to a specific version of a dependency so to be sure that in any case the used libraries don't get mixed up between different machines.
</p>
<p>
 To wrap an application into a container means that scaling becomes easier as by creating multiple containers there is the possibility to create a load balancer that redirects the requests to a container with less active load and if one of them gets too much traffic or dies unexpectedly due to an error the whole system will not go down and it will be easy to check the performance and metrics of that specific container.
</p>
<span class="image">
 <img src="https://i.ibb.co/kB0N16Y/img3.jpg" alt="rapresentation of scaling an application through redirecting requests towards the less busy container">
</span>

<h2>Installing Docker</h2>
<p>
   The <a href="https://docs.docker.com/">docker docs</a> provide exact and in-depth information about how to install it on your operative system. It is recommended to use a linux distribution as docker uses heavily linux under the hood and is built with it in mind. Docker runs natively on linux and the only version of window that run docker natively are Windows Server 2016 and Windows 10. Docker bases container on linux distributions so it might also be better to get accustomed to it but in any case it can be installed on most operative systems.
   <br>
   The following instructions are to install Docker Desktop. With it comes along the docker engine and everything else. Everything here will be done through the command line but once accustomed with it it will be very useful to have an interface to speed things up.
   <ol>
      <li><a href="https://docs.docker.com/desktop/install/mac-install/">MacOS</a></li>
      <li><a href="https://docs.docker.com/desktop/install/windows-install/">Windows</a></li>
      <li><a href="https://docs.docker.com/engine/install/#server">Linux distributions</a></li>
   </ol>
   To check if Docker is installed run <code>Docker -v</code> in the command line and the version and the build will be outputted.
</p>

<h2>Warming up</h2>
<p>
 By running in the command line <code>docker container run hello-world</code> docker will look for the <code>hello-world</code> image locally. It will not found it and will thus look it up on the internet to download it if a matching occurs. The output will be:
<pre><code>$ docker container run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
2db29710123e: Pull complete 
Digest: sha256:4e83453afed1b4fa1a3500525091dbfca6ce1e66903fd4c01ff015dbcb1ba33e
Status: Downloaded newer image for hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
   1. The Docker client contacted the Docker daemon.
   2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
      (amd64)
   3. The Docker daemon created a new container from that image which runs the
      executable that produces the output you are currently reading.
   4. The Docker daemon streamed that output to the Docker client, which sent it
      to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
   $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
   https://hub.docker.com/

For more examples and ideas, visit:
   https://docs.docker.com/get-started/</code></pre>
 Images are  immutable as they can't change after their build.
 <br>
 To list all the locally available images run in the command line <code>docker image ls</code>
<pre><code>$ docker image ls
REPOSITORY    TAG      IMAGE ID       CREATED         SIZE
hello-world   latest   feb5d9fea6a5   18 months ago   13.3kB
</code></pre>
 Everytime an image's build is completed it's possible to create a container. the <code>Dockerfile</code>instruction follow a pattern that resembles this:
<pre><code># start image from a previously built image
FROM *image*:*tag*

# run cli command to install some dependencies
# or to perform an operation
RUN *cli command*

# run the cli command that will be execute on creation
CMD *cli command executed on run*</code></pre>
</p>
<p>
 A container contains only what is required to run the application. It is an isolated environment that can communicate with other containers through the TCP/UDP method.
 <br>
 To see all the container that are currently running run in the cli <code>docker container ls</code>
<pre><code>$ docker container ls
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</code></pre>
   and to see all the exited containers add the <code>-a</code> flag:
<pre><code>$ docker container ls -a
CONTAINER ID   IMAGE         COMMAND   CREATED        STATUS                     PORTS     NAMES
914f05a2f6c3   hello-world   "/hello"  7 seconds ago   Exited (0) 4 seconds ago            clever_jones
</code></pre>
</p>
<p>
 The Docker cli is divided in three parts:
 <ol>
  <li>The docker cli tool that accepts a request</li>
  <li>The Docker daemon that manages the images and the containers</li>
  <li>A REST API used to communicate with the daemon</li>
 </ol>
 The Docker cli offers more than 50 different commands but the foundamentals and simplest ones are going to be used for 90% of the time:
 <dl>
  <dt>
   <code>docker image ls</code>
  </dt>
  <dd>Lists all the images</dd>
  <dt>
   <code>docker image pull *image*</code>
  </dt>
  <dt>
   gets an image from the registry and downloads it if there isn't one available locally
  </dt>
  <dt>
   <code>docker container run *image name*</code>
  </dt>
  <dd>
   creates and runs a new container based on an existing image. <br> the <code>-d</code> flag runs it in detached state
  </dd>
  <dt>
   <code>docker container stop *container name or id*</code>
  </dt>
  <dd>
   stops a running container
  </dd>
  <dt>
   <code>docker image rm *image name*</code>
  </dt>
  <dd>
   Removes a specific image
  </dd>
  <dt>
   <code>docker container ls</code>
  </dt>
  <dd>
   Lists all the container currently running. The <code>-a</code> flag lists also the stopped ones
  </dd>
  <dt>
  <dt>
   <code>docker container stop *container name or id*</code>
  </dt>
  <dd>
   Stops a running container
  </dd>
  <dt>
   <code>docker container rm *image id or name*</code>
  </dt>
  <dd>
   deletes a container by its id. It can also take the first few chars of the id and work anyway giving a warning only if there are more containers with an id that <i>start</i> the same. <br>Can accept multiple arguments
  </dd>
 </dl>
</p>

<p>
   Containerization works with everything and by pulling from the internet the image of an operative system it will be possible to run the <code>tty</code> interface with the <code>-t</code> flag. The sole problem is that although this will output the interface, it will still not send any of the inputs commands. To achieve it the flag <code>-i</code> will have to be put along so to actually send commands and receive output successfully. 
   <br>
   The flag <code>--name</code> allows for a custom name for a container. With a custom name will also be easier to stop or continue a container. Typing <code>docker pause *container name*</code> will stop the container with the specifed name and <code>docker unpause *container name*</code> will make it run again starting from where it was interrupted. 
   <br>
   Considering that containers are also piece of software that run in a fixed environment you can also communicate with them while they run. For this there is the flag <code>--exec</code>. A usage example could be to have a running instance of a database and use the flag to query some specific data or to run additional commands to a running instance of an operative instance. What if we have deployed our software in a container with a specific linux distribution and we want to check something while is running? A very simple <code>docker exec -it *container name* bash</code> will open the bash command line in the current terminal and with the <code>-it</code> flag it will be possible to interact with it.
   <br>
   Now that a lot has been put on the plate is time to see things in a more practical way.
</p>

<h2>Using containers</h2>
<p>
   Let's run a in a container a lightweight linux distribution: <a href="https://alpinelinux.org/">alpine</a>. When an image is not present locally docker will consult the official docker image registry at <a href="https://hub.docker.com/">docker hub</a>. There are, of course, other image registries like <a href="https://quay.io/">quay</a> but docker hub remians the central point to find images.
<pre><code>$ docker pull alpine
Using default tag: latest
latest: Pulling from library/alpine
f56be85fc22e: Pull complete 
Digest: sha256:124c7d2707904eea7431fffe91522a01e5a861a624ee31d03372cc1d138a3126
Status: Downloaded newer image for alpine:latest
<b>docker.io</b>/library/alpine:latest
</code></pre>
   Running <code>docker run alpine</code> will produce no output and although the container will be created it will immediately stop running:
<pre><code>$ docker run alpine 
$ docker container ls -a
CONTAINER ID   IMAGE     COMMAND     CREATED         STATUS                     PORTS     NAMES
0c21e8b38485   alpine    "/bin/sh"   9 seconds ago   Exited (0) 6 seconds ago             pensive_gagarin
</code></pre>
   Adding the <code>-it</code> flag the container will keep running and you'll be able to interact with it till you don't shut it down. By itself the containerized OS will open and will be possible to use it.
</p>
<span class="image">
   <img src="https://i.ibb.co/9bHKyRP/img4.png" alt="image showing interacting with a docker container running the alpine linux distro">
</span>
<p>
   to exit the container while using a shell the keyword <code>exit</code> will terminate the terminal and the container too. This works because you are currently using a bash shell in the container. Normally to stop a container would need to be done using the docker cli with <code>docker stop *container id or name*</code>
</p>

<h2>Building images</h2>
<p>
   Docker can perform a wide array of actions like copy files, run cli commands and use multiple images inside the current one. It improves the build of such instruction by dividing them into <i>layers</i> that gets executed simultaneously. Roughly talking, every line in the <code>Dockerfile</code> is a layer.
</p>
<p>
   With a bash script called <code>hello.sh</code>with the following code
<pre><code>echo "Hi from a Docker container!"</code></pre>
   and in the same directoy a <code>Dockerfile</code> with the following code it will be possible to containerize the file as it would be a fully blown application.
<pre><code># starting from the alpine image with tag 3.13 (which contains alpine 3.13)
FROM alpine:3.13

# set the '/app' directory as the working one
WORKDIR /app

# copy 'hello.sh' into the working directory (so '/app')
COPY hello.sh .

# 'RUN' is used to run terminal commands into the image. 
# This commands gives permissions to the file
RUN chmod +x hello.sh

# 'CMD' is similar to RUN but runs when the image is 
# executed and there can be only one per Dockerfile
CMD ./hello.sh
</code></pre>
   Running in the directoy with the two files the command <code>docker build . -t hello</code> will create an image following the various steps:
<pre><code>Sending build context to Docker daemon  3.072kB
Step 1/5 : FROM alpine:3.13
3.13: Pulling from library/alpine
72cfd02ff4d0: Pull complete 
Digest: sha256:469b6e04ee185740477efa44ed5bdd64a07bbdd6c7e5f5d169e540889597b911
Status: Downloaded newer image for alpine:3.13
   ---> 6b5c5e00213a
Step 2/5 : WORKDIR /app
   ---> Running in 238063f29511
Removing intermediate container 238063f29511
   ---> 993baed50ddb
Step 3/5 : COPY hello.sh .
   ---> 3818dc4285f3
Step 4/5 : RUN chmod +x hello.sh
   ---> Running in 152db25c29eb
Removing intermediate container 152db25c29eb
   ---> 7c1db39374e3
Step 5/5 : CMD ./hello.sh
   ---> Running in 587249037c6f
Removing intermediate container 587249037c6f
   ---> 1f3cbfdf42c0
Successfully built 1f3cbfdf42c0
Successfully tagged hello:latest
</code></pre>
   Using <code>docker run hello</code> will instantiate the container that will print <code>Hi from a Docker container!</code> for then stopping automatically.
</p>

<p>
   In the dockerfile you used certain keywords to build the images. You used <code>RUN</code> to execute some shell commands into the container and <code>CMD</code> but there is also a third one which is essential to develop serious images andis often confused with the other two: <code>ENTRYPOINT</code>.
   <br>
   <code>RUN</code> is the simplest of them all. It simply runs some command line code into the container and that's it. <code>CMD</code>, instead, is the final command of an image. There can be only one and at the end of the <code>Dockerfile</code> and gets executed during <code>docker run</code>.
   <br>
   <code>ENTRYPOINT</code> is similar to <code>CMD</code> with the foundamental difference that it allows for arguments when running the container. <code>CMD</code> can, and should, be used along <code>ENTRYPOINT</code> to set a default argument for the container creation. Let's say that a container needs a parameter. Something like a name. If the name is provided as an argument during docker run then the container would output something like
<pre><code>hi *name*!</code></pre>
   otherwise it would automatically set <code>User</code> as default name. The code for this example would be
<pre><code>FROM alpine:3.13

WORKDIR /app

COPY hello.sh .

RUN chmod +x ./hello.sh

# writing a command this way
ENTRYPOINT ["sh", "hello.sh"]
# will use the <i>exec form</i> that runs the
# command directly while otherwise it
# would use the shell form which means
# that the command will use all the
# shell conveniencies. Using the shell
# form breaks  the entrypoint and cmd
# concatenation

CMD ["User"]</code></pre>
   In this code the file <code>hello.sh</code> is simply
<pre><code>echo "Hi" $1
</code></pre>
   Running the command <code>docker build . -t new-hello</code> will output the expected behavior and use <i>User</i> as default argument:
<pre><code>$ docker run new-hello
Hi User
$ docker run new-hello Mark
Hi Mark</code></pre>
   A similar behavior is also used for images of operative systems. The command <code>docker run ubuntu</code>, for example, will automatically use as argument the <code>bash</code> keyword so that running the image will open by default the terminal to interact with it.
</p>

<h2>Storing a container's data</h2>
<p>
   When data is generated by a container it exists only inside of itself. To store the generated data there are two interconnected ways: <i>volumes</i> and <b>bind mounts</b>. Bind mounts connect a file or directory of the container to the host machine and everything that happens into the file or directory of the container happens in the host machine file or folder too while a volume is a space managed by docker can be migrated and shared easily based on bind mounts. The <code>-v</code> flag accepts as argument a string that contains that path of both the local machine and container file or directory separated by a column and create a volume at the same time. It is clearer with an example. Let's analyse the following image:
<pre><code>FROM alpine:3.13
WORKDIR /app

# creation of the file inside the container
RUN touch file.txt

# those two commands go together so that the 
# container can append the text to the bound
# file in the volume you can see the output
# at the same time
CMD echo "text" >> file.txt && cat file.txt

# to have this by itself in the CMD command
# would not work
# CMD cat file.txt</code></pre>
   The container related to this image would by itself just print <code>text</code> but by binding <code>file.txt</code> with a file with the same name on the hosting machine the container's file will have persistence over time. The bind amount can happend only through file with the same name so by creating a <code>file.txt</code> in the same directory of the Dockerfile the completed flag value would be
<pre><code>-v "$(pwd)/file.txt:/app/file.txt"</code></pre>
   The value can be divided into three parts:
   <ol>
      <li><code>$(pwd)/file.txt</code> is the absolute path for the bound file on the host maching. <code>$(pwd)</code> indicates the current directory</li>
      <li><code>:</code> separates the absolute path of the file on the host machine from the one in the container</li>
      <li><code>/app/file.txt</code> is the absolute path of the file in the container</li>
   </ol>
   In the following image is possible to see the result of running the container without using volumes and it simply outputs <code>text</code> while using the <code>-v</code> flag the container's file and the one on the host machine are connected and everytime a new container gets run the content persists although the containers will be different.
</p>
<span class="image">
   <img src="https://i.ibb.co/c3HvcW3/img5.png" alt="example usage of a docker valume using a file">
</span>
<p>
   The same holds true for directories too, of course. If in the current directory you delete <code>file.txt</code> and bind mount the <code>/app</code> directory with the current every change that will happen in the container's directory will persist. Although to mount to files they need to have the same name this is not true for directories.
</p>
<span class="image">
   <img src="https://i.ibb.co/xLK8N93/img6.png" alt="example usage of a docker valume using a directory">
</span>
<p>
   The most important note to bear in mind is that <i>routes are always absolute</i> and every attempt to use a relative one will result in an error.
<pre><code>docker run -v "./file.txt:/app/file.txt" bind-mount-example
docker: Error response from daemon: create $./file.txt: "$./file.txt" includes invalid characters for a local volume name, only "[a-zA-Z0-9][a-zA-Z0-9_.-]" are allowed. If you intended to pass a host directory, use absolute path</code></pre>
</p>

<h2>Ports</h2>
<p>
   A running container can communicate using URLs and the most important is the address <code>127.0.0.1</code>, usally called <code>localhost</code>, that refers to the machine itself. This is important to know because by itself a container is simply a virtual space where code runs so if an application can normally be seen on localhost on a specific port if it runs in a container it will not communicate with the host machine. Docker works with ports in two ways:
   <dl>
      <dt>Exposing a port</dt>
      <dd>To expose a certain port means that the container is listening on that port. It is useful especially for manual configuration and happens in the <code>Dockerfile</code></dd>
      <dt>Publishing a port</dt>
      <dd>To publish a port means to map a port of the container to one of the host machine so that it can be accessed while still running inside the container</dd>
   </dl>
   Let's analyse the following code for a <code>Dockerfile</code>:
<pre><code>FROM python

# will work also without exposing
# the port but is always better
# to not omit this line
EXPOSE 8000

WORKDIR /app

RUN touch data.json
RUN echo '{"message":"Hello"}' >> data.json

CMD ["python", "-m", "http.server"]  
</code></pre>
   This code uses python to create a web server. It simply serves every file inside the current folder, in this case <code>/app</code>. By creating a json file with some data that will be then received when visiting the related url.
</p>
<span class="image">
   <img src="https://i.ibb.co/27Yv1zz/img7.png" alt="">
</span>

<h2>Ending</h2>
<p>
   Docker is a foundamental part of general DevOps and although it might not be the tool that you'll be going to use the concepts of containers and virtualization are always the same and do not change between services. Containerization allows for an easier continuous integration and continuous deployment cycle but it still needs to be backed up by other practices to allow that everything runs as smooth as possible. Containers are a first but vital part of such processes.
</p>